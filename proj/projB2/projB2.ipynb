{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"projB2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project B2: Spam/Ham Classification - Build Your Own Model\n",
    "\n",
    "## Feature Engineering, Classification, and Cross-Validation\n",
    "## Due Date: Thursday, November 30th, 11:59 PM PDT\n",
    "You must submit this assignment to Gradescope by the on-time deadline, Thursday, November 30th, 11:59 PM. \n",
    "Please read the syllabus for the grace period policy. \n",
    "No late submissions beyond the grace period will be accepted. While course staff is happy to help you if you encounter difficulties with submission, we may not be able to respond to last-minute requests for assistance (TAs need to sleep, after all!). \n",
    "**We strongly encourage you to plan to submit your work to Gradescope several hours before the stated deadline.** \n",
    "This way, you will have ample time to reach out to staff for submission support.\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. \n",
    "While you may talk with others about this project, we ask that you **write your solutions individually**. \n",
    "If you discuss the assignments with others, please **include their names** in the collaborators cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "proj2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "In this project, you will build and improve on the concepts and functions you implemented in Project B1 to create your own classifier to distinguish spam emails from ham (non-spam) emails. We will evaluate your work based on your model's accuracy and written responses in this notebook.\n",
    "\n",
    "After this assignment, you should feel comfortable with the following:\n",
    "\n",
    "- Using `sklearn` libraries to process data and fit classification models,\n",
    "- Validating the performance of your model and minimizing overfitting, and\n",
    "- Generating and analyzing ROC curves.\n",
    "\n",
    "## Content Warning\n",
    "This is a **real-world** dataset– the emails you are trying to classify are actual spam and legitimate emails. As a result, some of the spam emails may be in poor taste or be considered inappropriate. We think the benefit of working with realistic data outweighs these inappropriate emails and wanted to warn you at the beginning of the project so that you are made aware.\n",
    "\n",
    "If you feel uncomfortable with this topic, **please contact your GSI or the instructors, or reach out via the Fall 2023 [extenuating circumstances form](https://docs.google.com/forms/d/e/1FAIpQLSffIhNMwsxP9Pd5l_9dzx_V4VffsNIOOjOexLT9VgUtmzw4AA/viewform).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to suppress all FutureWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "Grading is broken down into autograded answers and free responses. \n",
    "\n",
    "For autograded answers, the results of your code are compared to provided and/or hidden tests.\n",
    "\n",
    "For free response questions, readers will evaluate how well you answered the question and/or fulfilled the requirements of the question.\n",
    "\n",
    "Question | Manual | Points\n",
    "----|----|----\n",
    "1 | Yes | 6\n",
    "2a | Yes | 4\n",
    "2b | Yes | 2\n",
    "3 | Yes | 3\n",
    "4a | No | 5\n",
    "4b | No | 10\n",
    "Total | 4 | 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:41.341673Z",
     "start_time": "2019-04-03T20:17:41.330307Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Setup and Recap\n",
    "\n",
    "Here, we will provide a summary of Project B1 to remind you of how we cleaned the data, explored it, and implemented methods helpful in building your own model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loading",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Loading and Cleaning Data\n",
    "\n",
    "Remember that in email classification, our goal is to classify emails as spam or not spam (referred to as \"ham\") using features generated from the text in the email. \n",
    "\n",
    "The dataset consists of email messages and their labels (0 for ham, 1 for spam). Your labeled training dataset contains 8,348 labeled examples, and the unlabeled test set contains 1,000 unlabeled examples.\n",
    "\n",
    "Run the following cell to load the data into a `DataFrame`.\n",
    "\n",
    "The `train` `DataFrame` contains labeled data that you will use to train your model. It contains four columns:\n",
    "\n",
    "1. `id`: An identifier for the training example.\n",
    "1. `subject`: The subject of the email.\n",
    "1. `email`: The text of the email.\n",
    "1. `spam`: 1 if the email is spam, 0 if the email is ham (not spam).\n",
    "\n",
    "The `test` `DataFrame` contains 1,000 unlabeled emails. You will predict labels for these emails and submit your predictions to the autograder for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('spam_ham_data.zip') as item:\n",
    "    item.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: A&amp;L Daily to be auctioned in bankrupt...</td>\n",
       "      <td>URL: http://boingboing.net/#85534171\\n Date: N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: Wired: \"Stronger ties between ISPs an...</td>\n",
       "      <td>URL: http://scriptingnews.userland.com/backiss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: It's just too small                  ...</td>\n",
       "      <td>&lt;HTML&gt;\\n &lt;HEAD&gt;\\n &lt;/HEAD&gt;\\n &lt;BODY&gt;\\n &lt;FONT SIZ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: liberal defnitions\\n</td>\n",
       "      <td>Depends on how much over spending vs. how much...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: RE: [ILUG] Newbie seeks advice - Suse...</td>\n",
       "      <td>hehe sorry but if you hit caps lock twice the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            subject  \\\n",
       "0   0  Subject: A&L Daily to be auctioned in bankrupt...   \n",
       "1   1  Subject: Wired: \"Stronger ties between ISPs an...   \n",
       "2   2  Subject: It's just too small                  ...   \n",
       "3   3                      Subject: liberal defnitions\\n   \n",
       "4   4  Subject: RE: [ILUG] Newbie seeks advice - Suse...   \n",
       "\n",
       "                                               email  spam  \n",
       "0  URL: http://boingboing.net/#85534171\\n Date: N...     0  \n",
       "1  URL: http://scriptingnews.userland.com/backiss...     0  \n",
       "2  <HTML>\\n <HEAD>\\n </HEAD>\\n <BODY>\\n <FONT SIZ...     1  \n",
       "3  Depends on how much over spending vs. how much...     0  \n",
       "4  hehe sorry but if you hit caps lock twice the ...     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_training_data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Convert the emails to lowercase as the first step of text processing.\n",
    "#original_training_data['email'] = original_training_data['email'].str.lower()\n",
    "#test['email'] = test['email'].str.lower()\n",
    "\n",
    "original_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to explore the dataset above along with any specific spam and ham emails that interest you. Keep in mind that our data may contain missing values, which are handled in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.203231Z",
     "start_time": "2019-04-03T20:17:42.185104Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1fb39d9b651ca1b",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before imputation:\n",
      "id         0\n",
      "subject    6\n",
      "email      0\n",
      "spam       0\n",
      "dtype: int64\n",
      "------------\n",
      "After imputation:\n",
      "id         0\n",
      "subject    0\n",
      "email      0\n",
      "spam       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill any missing or NAN values.\n",
    "print('Before imputation:')\n",
    "print(original_training_data.isnull().sum())\n",
    "original_training_data = original_training_data.fillna('')\n",
    "print('------------')\n",
    "print('After imputation:')\n",
    "print(original_training_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Validation Split\n",
    "\n",
    "Recall that the training data we downloaded is all the data we have available for both training models and **validating** the models that we train. We, therefore, split the training data into separate training and validation datasets. You will need this **validation data** to assess the performance of your classifier once you are finished training. \n",
    "\n",
    "As in Project B1, we set the seed (`random_state`) to 42. **Do not modify this in the following questions, as our tests depend on this random seed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.317970Z",
     "start_time": "2019-04-03T20:17:42.294532Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-873194ed3e686dfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This creates a 90/10 train-validation split on our labeled data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(original_training_data, test_size = 0.1, random_state = 42)\n",
    "\n",
    "# We must do this in order to preserve the ordering of emails to labels for words_in_texts.\n",
    "train = train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "feat-eng",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We need a numeric feature matrix $\\mathbb{X}$ and a vector of corresponding binary labels $\\mathbb{Y}$ to train a logistic regression model. In Project B1, we implemented the function `words_in_texts`, which creates numeric features derived from the email text and uses those features for logistic regression. \n",
    "\n",
    "For this project, we have provided you with an implemented version of `words_in_texts`. Remember that the function outputs a 2-dimensional `NumPy` array containing one row for each email text. The row should contain a 0 or a 1 for each word in the list: 0 if the word doesn't appear in the text and 1 if the word does. \n",
    "\n",
    "Run the following cell to see how the function works on some text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from projB2_utils import words_in_texts\n",
    "\n",
    "words_in_texts(['hello', 'bye', 'world'], pd.Series(['hello', 'hello worldhello']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "classification",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## EDA and Basic Classification\n",
    "\n",
    "In Project B1, we proceeded to visualize the frequency of different words for both spam and ham emails and used `words_in_texts(words, train['email'])` to directly to train a classifier. We also provided a simple set of 5 words that might be useful as features to distinguish spam/ham emails. \n",
    "\n",
    "We then built a model using the [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier from `sklearn`.\n",
    "\n",
    "Run the following cell to see the performance of a simple model using these words and the `train` `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.726012Z",
     "start_time": "2019-04-03T20:17:43.498088Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q4-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0]]),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n",
    "\n",
    "X_train = words_in_texts(some_words, train['email'])\n",
    "Y_train = np.array(train['spam'])\n",
    "\n",
    "X_train[:5], Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:44.593918Z",
     "start_time": "2019-04-03T20:17:43.783872Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q5-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7532277385864502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "training_accuracy = model.score(X_train, Y_train)\n",
    "print(\"Training Accuracy: \", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our models, we are evaluating the accuracy of the training set, which may provide a misleading accuracy measure. In Project B1, we calculated various metrics to lead us to consider more ways of evaluating a classifier, in addition to overall accuracy. Below is a reference to those concepts.\n",
    "\n",
    "Presumably, our classifier will be used for **filtering**, i.e., preventing messages labeled `spam` from reaching someone's inbox. There are two kinds of errors we can make:\n",
    "- **False positive (FP)**: A ham email gets flagged as spam and filtered out of the inbox.\n",
    "- **False negative (FN)**: A spam email gets mislabeled as ham and ends up in the inbox.\n",
    "\n",
    "To be clear, we label spam emails as 1 and ham emails as 0. These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier in addition to overall accuracy:\n",
    "\n",
    "**Precision**: Measures the proportion of emails flagged as spam that are actually spam. Mathematically, $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$.\n",
    "\n",
    "**Recall**: Measures the proportion  of spam emails that were correctly flagged as spam. Mathematically, $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$.\n",
    "\n",
    "**False positive rate**: Measures the proportion  of ham emails that were incorrectly flagged as spam. Mathematically, $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$.\n",
    "\n",
    "The below graphic (modified slightly from [Wikipedia](https://en.wikipedia.org/wiki/Precision_and_recall)) may help you understand precision and recall visually:<br />\n",
    "<center>\n",
    "<img alt=\"precision_recall\" src=\"precision_recall.png\" width=\"600px;\" />\n",
    "</center>\n",
    "\n",
    "Note that a True Positive (TP) is a spam email that is classified as spam, and a True Negative (TN) is a ham email that is classified as ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Moving Forward - Building Your Own Model\n",
    "\n",
    "With this in mind, it is now your task to make the spam filter more accurate. To get full credit on the accuracy part of this assignment, you must get at least **85%** accuracy on both the train and test set (see Q4 for the partial credit breakdown). To see your accuracy on the test set, you will use your classifier to predict every email in the `test` `DataFrame` and upload your predictions to Gradescope.\n",
    "\n",
    "**Gradescope limits to 3 submissions per day to meet the threshold**. You will be able to see your accuracy on the entire test set when submitting to Gradescope. In the case that you are approved for an extension, you are granted 3 more submissions for each day the deadline has been extended.\n",
    "\n",
    "Here are some ideas for improving your model:\n",
    "\n",
    "1. Finding better features based on the email text. Some example features are:\n",
    "    1. Number of characters in the subject/body\n",
    "    1. Number of words in the subject/body\n",
    "    1. Use of punctuation (e.g., how many '!'s were there?)\n",
    "    1. Number/percentage of capital letters \n",
    "    1. Whether the email is a reply to an earlier email or a forwarded email\n",
    "1. Finding better (and/or more) words to use as features. Which words are the best at distinguishing emails? This requires digging into the email text itself. \n",
    "1. Better data processing. For example, many emails contain HTML as well as text. You can consider extracting the text from the HTML to help you find better words. Or, you can match HTML tags themselves, or even some combination of the two.\n",
    "1. Model selection. You can adjust the parameters of your model (e.g. the penalty type, the regularization parameter, or any arguments in `LogisticRegression`) to achieve higher accuracy. Recall that you should use cross-validation to do feature and model selection properly! Otherwise, you will likely overfit to your training data.\n",
    "    1. We have imported `GridSearchCV` for you. You may use sklearn's `GridSearchCV` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)) class to perform cross-validation. You do not need to code your own cross-validation from scratch, though you are welcome to do so.\n",
    "\n",
    "Here's an example of how to use `GridSearchCV`. Suppose we wanted to experiment with 3 different solvers (numerical methods for optimizing the mode) models for a `LogisticRegression` model `lr_model`. \n",
    "1. We could define a dictionary specifying the hyperparameters and the specific values we want to try out like so: `parameters = {'solver':[{'lbfgs', 'liblinear', 'newton-cg', 'saga']}`.\n",
    "2. Running `grid = GridSearchCV(estimator=lr_model, param_grid=parameters)` would give us a model for each combination of hyperparameters we are testing - in this case, just 4 models.\n",
    "3. We fit each model to some training data `X_train` and `Y_train` using `grid_result = grid.fit(X_train, Y_train)`.\n",
    "4. Indexing into `grid_result.cv_results_` with a particular metric (in this case, `mean_test_score`), we get an array with the scores corresponding to each of the models. `grid_result.cv_results_['mean_test_score']`.\n",
    "Feel free to experiment with other hyperparameters and metrics as well, the documentation is your friend!     \n",
    "       \n",
    "You may use whatever method you prefer in order to create features, but **you may only use the packages we've imported for you in the cell below or earlier in this notebook**. In addition, **you are only allowed to train logistic regression models**. No decision trees, random forests, k-nearest-neighbors, neural nets, etc.\n",
    "\n",
    "We have not provided any code to do this, so feel free to create as many cells as you need in order to tackle this task. However, answering questions 1, 2, and 3 should help guide you.\n",
    "\n",
    "**Note:** You may want to use your **validation data** to evaluate your model and get a better sense of how it will perform on the test set. However, you may overfit your validation set if you try to optimize your validation accuracy too much. Alternatively, you can perform cross-validation on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# you may use any of these to create your features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam Word</th>\n",
       "      <th>Spam Count</th>\n",
       "      <th>Ham Word</th>\n",
       "      <th>Ham Count</th>\n",
       "      <th>Spam Prop</th>\n",
       "      <th>Ham Prop</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you</td>\n",
       "      <td>10736</td>\n",
       "      <td>you</td>\n",
       "      <td>9613</td>\n",
       "      <td>5.016822</td>\n",
       "      <td>1.548486</td>\n",
       "      <td>3.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>18887</td>\n",
       "      <td>to</td>\n",
       "      <td>41322</td>\n",
       "      <td>8.825701</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>2.169451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>14987</td>\n",
       "      <td>and</td>\n",
       "      <td>31747</td>\n",
       "      <td>7.003271</td>\n",
       "      <td>5.113885</td>\n",
       "      <td>1.889386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;td</td>\n",
       "      <td>6691</td>\n",
       "      <td>&lt;td</td>\n",
       "      <td>9806</td>\n",
       "      <td>3.126636</td>\n",
       "      <td>1.579575</td>\n",
       "      <td>1.547061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>13644</td>\n",
       "      <td>of</td>\n",
       "      <td>31970</td>\n",
       "      <td>6.375701</td>\n",
       "      <td>5.149807</td>\n",
       "      <td>1.225894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>this</td>\n",
       "      <td>5056</td>\n",
       "      <td>this</td>\n",
       "      <td>7913</td>\n",
       "      <td>2.362617</td>\n",
       "      <td>1.274646</td>\n",
       "      <td>1.087971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>for</td>\n",
       "      <td>7884</td>\n",
       "      <td>for</td>\n",
       "      <td>16228</td>\n",
       "      <td>3.684112</td>\n",
       "      <td>2.614046</td>\n",
       "      <td>1.070066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>are</td>\n",
       "      <td>3901</td>\n",
       "      <td>are</td>\n",
       "      <td>7497</td>\n",
       "      <td>1.822897</td>\n",
       "      <td>1.207635</td>\n",
       "      <td>0.615262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>7706</td>\n",
       "      <td>in</td>\n",
       "      <td>20317</td>\n",
       "      <td>3.600935</td>\n",
       "      <td>3.272713</td>\n",
       "      <td>0.328222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>with</td>\n",
       "      <td>4024</td>\n",
       "      <td>with</td>\n",
       "      <td>9782</td>\n",
       "      <td>1.880374</td>\n",
       "      <td>1.575709</td>\n",
       "      <td>0.304665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is</td>\n",
       "      <td>6950</td>\n",
       "      <td>is</td>\n",
       "      <td>18863</td>\n",
       "      <td>3.247664</td>\n",
       "      <td>3.038499</td>\n",
       "      <td>0.209165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>on</td>\n",
       "      <td>3863</td>\n",
       "      <td>on</td>\n",
       "      <td>10958</td>\n",
       "      <td>1.805140</td>\n",
       "      <td>1.765142</td>\n",
       "      <td>0.039998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I</td>\n",
       "      <td>4245</td>\n",
       "      <td>I</td>\n",
       "      <td>14449</td>\n",
       "      <td>1.983645</td>\n",
       "      <td>2.327481</td>\n",
       "      <td>-0.343836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>9789</td>\n",
       "      <td>a</td>\n",
       "      <td>31901</td>\n",
       "      <td>4.574299</td>\n",
       "      <td>5.138692</td>\n",
       "      <td>-0.564393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>that</td>\n",
       "      <td>4141</td>\n",
       "      <td>that</td>\n",
       "      <td>16028</td>\n",
       "      <td>1.935047</td>\n",
       "      <td>2.581830</td>\n",
       "      <td>-0.646783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>20495</td>\n",
       "      <td>the</td>\n",
       "      <td>64272</td>\n",
       "      <td>9.577103</td>\n",
       "      <td>10.353093</td>\n",
       "      <td>-0.775990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Spam Word  Spam Count Ham Word  Ham Count  Spam Prop   Ham Prop      Diff\n",
       "4        you       10736      you       9613   5.016822   1.548486  3.468337\n",
       "1         to       18887       to      41322   8.825701   6.656250  2.169451\n",
       "2        and       14987      and      31747   7.003271   5.113885  1.889386\n",
       "9        <td        6691      <td       9806   3.126636   1.579575  1.547061\n",
       "3         of       13644       of      31970   6.375701   5.149807  1.225894\n",
       "10      this        5056     this       7913   2.362617   1.274646  1.087971\n",
       "6        for        7884      for      16228   3.684112   2.614046  1.070066\n",
       "14       are        3901      are       7497   1.822897   1.207635  0.615262\n",
       "7         in        7706       in      20317   3.600935   3.272713  0.328222\n",
       "13      with        4024     with       9782   1.880374   1.575709  0.304665\n",
       "8         is        6950       is      18863   3.247664   3.038499  0.209165\n",
       "15        on        3863       on      10958   1.805140   1.765142  0.039998\n",
       "11         I        4245        I      14449   1.983645   2.327481 -0.343836\n",
       "5          a        9789        a      31901   4.574299   5.138692 -0.564393\n",
       "12      that        4141     that      16028   1.935047   2.581830 -0.646783\n",
       "0        the       20495      the      64272   9.577103  10.353093 -0.775990"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate spam and ham emails\n",
    "spam_emails = original_training_data[original_training_data[\"spam\"] == 1]\n",
    "ham_emails = original_training_data[original_training_data[\"spam\"] == 0]\n",
    "\n",
    "spam_tokenized_words = ' '.join(spam_emails['email']).split()\n",
    "spam_word_counts = Counter(spam_tokenized_words)\n",
    "top_spam_words = spam_word_counts.most_common(20)\n",
    "\n",
    "ham_tokenized_words = ' '.join(ham_emails['email']).split()\n",
    "ham_word_counts = Counter(ham_tokenized_words)\n",
    "top_ham_words = ham_word_counts.most_common(20)\n",
    "\n",
    "# Create DataFrames with top words for spam and ham\n",
    "top_spam_df = pd.DataFrame({\n",
    "    'Spam Word': [word[0] for word in top_spam_words],\n",
    "    'Spam Count': [word[1] for word in top_spam_words]\n",
    "})\n",
    "\n",
    "top_ham_df = pd.DataFrame({\n",
    "    'Ham Word': [word[0] for word in top_ham_words],\n",
    "    'Ham Count': [word[1] for word in top_ham_words]\n",
    "})\n",
    "\n",
    "merged_df = pd.merge(top_spam_df, top_ham_df, left_on='Spam Word', right_on='Ham Word', how='inner')\n",
    "merged_df[\"Spam Prop\"] = merged_df[\"Spam Count\"]/ len(spam_emails)\n",
    "merged_df[\"Ham Prop\"] = merged_df[\"Ham Count\"]/ len(ham_emails)\n",
    "merged_df[\"Diff\"] = merged_df[\"Spam Prop\"]- merged_df[\"Ham Prop\"]\n",
    "\n",
    "merged_df2 = merged_df.sort_values(\"Diff\", ascending = False)\n",
    "merged_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your processing function, processed data, and model here. \n",
    "# You may find it helpful to look through the rest of the questions first!\n",
    "\n",
    "# Number of characters in the subject/body\n",
    "\n",
    "# Number of words in the subject/body\n",
    "def num_words(email):\n",
    "    # string_wo_quotes = email.replace('\"', '').replace(\"'\", '')\n",
    "    # print(string_wo_quotes)\n",
    "    return len(email.split())\n",
    "\n",
    "# Use of punctuation (e.g., how many '!'s were there?)\n",
    "def count_punc(email):\n",
    "    #print(email)\n",
    "    punctuations = re.findall(r'[^\\w\\s]', email)\n",
    "    #print(punctuations)\n",
    "    return len(punctuations)\n",
    "\n",
    "def prop_punc(email):\n",
    "    if pd.isna(email):\n",
    "        return 0\n",
    "        \n",
    "    if len(email) == 0:\n",
    "        return 0\n",
    "        \n",
    "    #print(email)\n",
    "    punctuations = re.findall(r'[^\\w\\s]', email)\n",
    "    #print(punctuations)\n",
    "    return len(punctuations)/len(email)\n",
    "\n",
    "def prop_digit(email):\n",
    "    if pd.isna(email):\n",
    "        return 0  \n",
    "    if len(email) == 0:\n",
    "        return 0\n",
    "        \n",
    "    digits = re.findall(r'\\d', email)\n",
    "   \n",
    "    return len(digits) / len(email)\n",
    "\n",
    "# Number/percentage of capital letters in subject line\n",
    "def prop_caps(subject):\n",
    "    if pd.isna(subject):\n",
    "        return 0\n",
    "    if len(subject) == 0:\n",
    "        return 0\n",
    "    return sum(1 for c in subject if c.isupper())/len(subject)\n",
    "\n",
    "def reply_or_forward(subject):\n",
    "    if pd.isna(subject):\n",
    "        return 0\n",
    "        \n",
    "    if len(subject) == 0:\n",
    "        return 0\n",
    "\n",
    "    subject_lower = subject.lower()\n",
    "    return 1 if \"fwd:\" in subject_lower or \"re:\" in subject_lower else 0\n",
    "\n",
    "\n",
    "#2. Finding better (and/or more) words to use as features.\n",
    "more_words = ['drug', 'bank', 'prescription', 'memo', 'private', 'body', 'business', 'money', \n",
    "              'click', '100%', 'free', 'really', 'show', 'the', 'you', 'subscribe', \n",
    "              'luxury', 'call', 'deal', 'of']\n",
    "\n",
    "#3. Better data processing, extract text from HTML\n",
    "def extract_text_from_html(email):\n",
    "    if \"<html>\" not in email.lower():\n",
    "        return email\n",
    "    \n",
    "    inside_tag = False\n",
    "    result = []\n",
    "\n",
    "    for char in email:\n",
    "        if char == '<':\n",
    "            inside_tag = True\n",
    "        elif char == '>':\n",
    "            inside_tag = False\n",
    "        elif not inside_tag:\n",
    "            result.append(char)\n",
    "\n",
    "    extracted_text = ''.join(result)\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_df(df):\n",
    "    #3\n",
    "    df[\"email\"] = df[\"email\"].apply(extract_text_from_html)\n",
    "\n",
    "    #2\n",
    "    w_i_t_df = pd.DataFrame(words_in_texts(more_words, df[\"email\"]))\n",
    "    #df = df.join(w_i_t_df)\n",
    "    w_i_t_df[\"id\"] = df[\"id\"]\n",
    "    df = df.merge(w_i_t_df, left_on='id', right_on='id')\n",
    "\n",
    "    #1\n",
    "    df[\"prop_punc_s\"] = df[\"subject\"].apply(prop_punc)\n",
    "    df[\"prop_punc_e\"] = df[\"email\"].apply(prop_punc)\n",
    "    \n",
    "    df[\"prop_caps_s\"] = df[\"subject\"].apply(prop_caps)\n",
    "    df[\"prop_caps_e\"] = df[\"email\"].apply(prop_caps)\n",
    "\n",
    "    df[\"prop_digit_s\"] = df[\"subject\"].apply(prop_digit)\n",
    "    df[\"prop_digit_e\"] = df[\"email\"].apply(prop_digit)\n",
    "\n",
    "    df[\"re_or_fwd\"] = df[\"subject\"].apply(reply_or_forward)\n",
    "\n",
    "    #df[\"num_words\"] = df[\"email\"].apply(num_words)\n",
    "    df.columns = df.columns.astype(str)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train.copy()\n",
    "new_val = val.copy()\n",
    "new_test = test.copy()\n",
    "\n",
    "new_train = new_df(new_train)\n",
    "new_val = new_df(new_val)\n",
    "new_test = new_df(new_test)\n",
    "\n",
    "#new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>prop_punc_s</th>\n",
       "      <th>prop_punc_e</th>\n",
       "      <th>prop_caps_s</th>\n",
       "      <th>prop_caps_e</th>\n",
       "      <th>prop_digit_s</th>\n",
       "      <th>prop_digit_e</th>\n",
       "      <th>re_or_fwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: CERT Advisory CA-2002-21 Vulnerabilit...</td>\n",
       "      <td>\\n \\n -----BEGIN PGP SIGNED MESSAGE-----\\n \\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.030932</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.062121</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.015893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: ADV: Affordable Life Insurance ddbfk\\n</td>\n",
       "      <td>Low-Cost Term-Life Insurance!\\n SAVE up to 70%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.098318</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.058215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: CAREER OPPORTUNITY.  WORK FROM HOME\\n</td>\n",
       "      <td>------=_NextPart_000_00A0_03E30A1A.B1804B54\\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.372071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: Marriage makes both sexes happy\\n</td>\n",
       "      <td>URL: http://www.newsisfree.com/click/-3,848315...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.072539</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.031088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: Re: [SAtalk] SA very slow (hangs?) on...</td>\n",
       "      <td>On Thursday 29 August 2002 16:39 CET Mike Burg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.154180</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.028230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            subject  \\\n",
       "0   0  Subject: CERT Advisory CA-2002-21 Vulnerabilit...   \n",
       "1   1    Subject: ADV: Affordable Life Insurance ddbfk\\n   \n",
       "2   2     Subject: CAREER OPPORTUNITY.  WORK FROM HOME\\n   \n",
       "3   3         Subject: Marriage makes both sexes happy\\n   \n",
       "4   4  Subject: Re: [SAtalk] SA very slow (hangs?) on...   \n",
       "\n",
       "                                               email  0  1  2  3  4  5  6  \\\n",
       "0  \\n \\n -----BEGIN PGP SIGNED MESSAGE-----\\n \\n ...  0  0  0  1  0  1  0   \n",
       "1  Low-Cost Term-Life Insurance!\\n SAVE up to 70%...  0  0  0  0  0  0  0   \n",
       "2  ------=_NextPart_000_00A0_03E30A1A.B1804B54\\n ...  0  0  0  0  0  0  0   \n",
       "3  URL: http://www.newsisfree.com/click/-3,848315...  0  0  0  0  0  0  0   \n",
       "4  On Thursday 29 August 2002 16:39 CET Mike Burg...  0  0  0  0  0  0  0   \n",
       "\n",
       "   ...  17  18  19  prop_punc_s  prop_punc_e  prop_caps_s  prop_caps_e  \\\n",
       "0  ...   1   0   1     0.054545     0.030932     0.218182     0.062121   \n",
       "1  ...   0   0   1     0.043478     0.098318     0.152174     0.058215   \n",
       "2  ...   0   0   0     0.044444     0.020619     0.666667     0.372071   \n",
       "3  ...   0   0   0     0.024390     0.072539     0.048780     0.031088   \n",
       "4  ...   0   0   1     0.113924     0.154180     0.075949     0.028230   \n",
       "\n",
       "   prop_digit_s  prop_digit_e  re_or_fwd  \n",
       "0      0.109091      0.015893          0  \n",
       "1      0.000000      0.025873          0  \n",
       "2      0.000000      0.136832          0  \n",
       "3      0.000000      0.062176          0  \n",
       "4      0.000000      0.021716          1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182 0.8839345135099161\n"
     ]
    }
   ],
   "source": [
    "X_train = new_train.iloc[:, 4:]\n",
    "Y_train = new_train['spam']\n",
    "\n",
    "X_val = new_val.iloc[:, 4:]\n",
    "Y_val = new_val['spam']\n",
    "\n",
    "X_test = new_test.iloc[:, 3:]\n",
    "\n",
    "model = LogisticRegression(fit_intercept=True, penalty='l2')\n",
    "model.fit(X_train, Y_train)\n",
    "val_pred = model.predict(X_val)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print(accuracy_score(Y_val, val_pred), accuracy_score(Y_train, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>prop_punc_s</th>\n",
       "      <th>prop_punc_e</th>\n",
       "      <th>prop_caps_s</th>\n",
       "      <th>prop_caps_e</th>\n",
       "      <th>prop_digit_s</th>\n",
       "      <th>prop_digit_e</th>\n",
       "      <th>re_or_fwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.030932</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.062121</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.015893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.098318</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.058215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.372071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.072539</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.031088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.154180</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.028230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.052111</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.022427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.102767</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.039526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.035484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.033877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>0.055788</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.044630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7  8  9  ...  17  18  19  prop_punc_s  prop_punc_e  \\\n",
       "0    0  0  0  1  0  1  0  0  0  0  ...   1   0   1     0.054545     0.030932   \n",
       "1    0  0  0  0  0  0  0  0  0  0  ...   0   0   1     0.043478     0.098318   \n",
       "2    0  0  0  0  0  0  0  0  0  0  ...   0   0   0     0.044444     0.020619   \n",
       "3    0  0  0  0  0  0  0  0  1  0  ...   0   0   0     0.024390     0.072539   \n",
       "4    0  0  0  0  0  0  0  0  0  0  ...   0   0   1     0.113924     0.154180   \n",
       "..  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..          ...          ...   \n",
       "995  0  0  0  0  0  0  0  0  0  1  ...   0   0   1     0.073171     0.071900   \n",
       "996  0  0  0  0  0  0  0  0  0  0  ...   0   0   1     0.055556     0.102767   \n",
       "997  0  0  0  0  0  0  0  0  0  0  ...   0   0   0     0.074074     0.067742   \n",
       "998  0  0  0  0  0  0  0  0  0  0  ...   0   0   1     0.085106     0.053952   \n",
       "999  0  0  0  0  0  1  0  1  1  0  ...   0   0   0     0.075758     0.055788   \n",
       "\n",
       "     prop_caps_s  prop_caps_e  prop_digit_s  prop_digit_e  re_or_fwd  \n",
       "0       0.218182     0.062121      0.109091      0.015893          0  \n",
       "1       0.152174     0.058215      0.000000      0.025873          0  \n",
       "2       0.666667     0.372071      0.000000      0.136832          0  \n",
       "3       0.048780     0.031088      0.000000      0.062176          0  \n",
       "4       0.075949     0.028230      0.000000      0.021716          1  \n",
       "..           ...          ...           ...           ...        ...  \n",
       "995     0.097561     0.052111      0.024390      0.022427          1  \n",
       "996     0.138889     0.039526      0.000000      0.000000          1  \n",
       "997     0.111111     0.035484      0.000000      0.009677          1  \n",
       "998     0.191489     0.033877      0.000000      0.002509          1  \n",
       "999     0.181818     0.044630      0.000000      0.002789          0  \n",
       "\n",
       "[1000 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1\n",
    "\n",
    "In the following cell, describe the process of improving your model. You should use at least 2-3 sentences each to address the following questions:\n",
    "\n",
    "1. How did you find better features for your model?\n",
    "2. What did you try that worked or didn't work?\n",
    "3. What was surprising in your search for good features?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initially I followed all the suggestions like finding the percent of capital letter in subject etc. But I only got around 50% accuracy for the validation set. I then decided to apply all these filters for both the subject and email. And it also took a significant amount of time to find the most appeared word in spam and ham emails to decide on the best words to use.\n",
    "\n",
    "2. I thought that num punc would be very efficient, but I saw some emails that are not spam has very high number of punctuations it turned out that it was written in html thus detected lots of non characters. Did some html extraction and it improved the accuracy. Also, the number of punctuations really does not matter, because the length of emails varies, so I tried proportion of punctuations intead.\n",
    "\n",
    "4. Some words are surprisingly very frequently used in spam email like \"you\", \"to\", \"and\". Try including number of words in the email. Does not improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q8",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "In the cell below, show a visualization you used to select features for your model. \n",
    "\n",
    "Please include:\n",
    "\n",
    "1. A plot showing something meaningful about the data that helped you during feature selection, model selection, or both.\n",
    "2. Two or three sentences describing what you plotted and its implications with respect to your features.\n",
    "\n",
    "Feel free to create as many plots as you want in your feature selection process, but select only one for the response cell below.\n",
    "\n",
    "**You should not just produce an identical visualization to Question 3 in Project B1.** For this section, we’d like you to go beyond the analysis you performed in Project B1. Choose some plot other than the 1-dimensional distribution of some quantity for spam and ham emails. In particular, do not produce a bar plot of proportions like you created in Question 3 of Project B1. Any other plot is acceptable, **as long as it comes with thoughtful commentary.** Here are some ideas:\n",
    "\n",
    "1. Consider the correlation between multiple features (look up correlation plots and `sns.heatmap` ([documentation](https://seaborn.pydata.org/generated/seaborn.heatmap.html)). \n",
    "1. Try to show redundancy in a group of features (e.g., `body` and `html` might co-occur relatively frequently, or you might be able to design a feature that captures all HTML tags and compares them to these). \n",
    "1. Visualize which words have high or low values for helpful statistics.\n",
    "1. Visually depict whether spam emails tend to be wordier (in some sense) than ham emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2a\n",
    "\n",
    "Generate your visualization in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='variable', ylabel='value'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "melt_re_or_fwd = new_train[['spam', 're_or_fwd']].melt('spam')\n",
    "sns.barplot(x = melt_re_or_fwd['variable'], y = melt_re_or_fwd['value'], hue = melt_re_or_fwd['spam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2b\n",
    "\n",
    "Write your commentary in the cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the melt function introduced from B1, I comparethe proportion of spam and ham emails that are either fowarded email or replies. For the first visualization there is a clear difference in height between spam and ham emails, that emails that are either fowarded email or replies are most likely to be ham emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3: ROC Curve\n",
    "\n",
    "In most cases, we won't be able to get 0 false positives and 0 false negatives, so we have to compromise. For example, in the case of cancer screenings, false negatives are comparatively worse than false positives — a false negative means that a patient might not discover that they have cancer until it's too late. In contrast, a patient can receive another screening for a false positive.\n",
    "\n",
    "Recall that logistic regression calculates the probability that an example belongs to a particular class. To classify an example, we say that an email is spam if our classifier gives it $\\ge 0.5$ probability of being spam. However, **we can adjust that cutoff threshold**: We can say that an email is spam only if our classifier gives it $\\ge 0.7$ probability of being spam, for example. This is how we can trade off false positives and false negatives.\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve shows this trade-off for each possible cutoff probability. In the cell below, plot an ROC curve for your final classifier (the one you use to make predictions for Gradescope) on the training data. Refer to Lecture 23 to see how to plot an ROC curve.\n",
    "\n",
    "**Hint**: You'll want to use the `.predict_proba` method for your classifier instead of `.predict` to get probabilities instead of binary predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAHHCAYAAACbXt0gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGbElEQVR4nO3de3xU1b3///ckmYRcIATFQLgFgSRcGhGsEqW0Itp4rALWHxQ9rWnVtFJszxerxUMBK0ektUVbKNRauRxOVbCCWG0ppYCimFZRQSCAwYzBJIZrQpJJMpPM/v0RMhCTwCRz2dmZ1/Px8MHO7DUrn70Imbdr7722zTAMQwAAAOiQCLMLAAAAsDLCFAAAgB8IUwAAAH4gTAEAAPiBMAUAAOAHwhQAAIAfCFMAAAB+IEwBAAD4IcrsArq6Dz74QIZhyG63m10KAADwkdvtls1m05VXXnnRtsxMBZlhGArWIvOGYcjlcgWtfzRinEODcQ4Nxjl0GOvQCNY4t+fzm5mpIGuakfrSl74U8L6dTqfy8/M1dOhQxcXFBbx/NGKcQ4NxDg3GOXQY69AI1jh/9NFHPrdlZgoAAMAPhCkAAAA/EKYAAAD8QJgCAADwA2EKAADAD4QpAAAAPxCmAAAA/GCZdaaOHz+uXbt26aOPPtK+ffuUn5+v2tpajRw5Uhs2bPCr77y8PK1atUp79uyR0+lUSkqKsrOzlZuby9ogAADggiwTpl5//XU98cQTAe937dq1evzxx2UYhvr06aO+ffuqoKBAK1as0JYtW/T888+rZ8+eAf++AACga7BMmEpISNC1116rUaNGadSoUXI4HFqyZIlffe7bt0+LFi2SJD322GOaNm2abDabysrKdP/992v//v2aN2+eli5dGohDAAAAXZBlwtQdd9yhO+64w/u1v6f2JGn58uXyeDyaMmWKpk+f7n09OTlZS5Ys0c0336wtW7bo4MGDysjI8Pv7AQCAridsL0Cvrq7Wzp07JUnTpk1rsT81NVXjxo2TJG3evDmktQEAAOsI2zCVn58vl8ul6OhoZWZmttpm7NixkqQ9e/aEsjQAAGAhljnNF2iFhYWSpJSUFNnt9lbbDBw4sFnbjjIMQ06n068+WlNTU9PsTwQH4xwajHNoMM7BVV3jlnF2u7amVjUuj06cqlS3Gner7evrPSo5US3ZbJKkwpIzioq07jzHoaJydYuOVMTZ4wmFhoZ6DUxqUGpqYH+mDcOQzcfjCNswVVFRIUlKTExss03Tvqa2HeV2u5Wfn+9XHxficDiC1jfOYZxDg3EODcb5HI/H0PEz9fJ4DDldHlVUNyjCJhWW1Sm+28WDza78KnWPjVBljaeNFiWBLRgtDOgdrdRkR8D7jY6O9qld2Iapuro6SWpzVko6N4hNbTvKbrdr6NChfvXRmpqaGjkcDqWmpio2Njbg/aMR4xwajHNodKVxNgxDJypq1dBgtNh3oqJWHx4+oQOO0+rds/XjLK+q08FPywNSS9tByjfxsVFKjI+WYUhlp2v05eG9A1KXGcpO1eiqjN4K1eRUfX29kuNrA/4zXVBQ4HPbsA1TMTExkhpnjdricrmate0om80W1MU/Y2NjWVw0BBjn0GCcQyOQ41xTV69aV32z16pr3Nr5YYniukXpo4IT6h4X7dOH656Pjyuum12O0jOKjrrwrJCr3rcAc6T4jE/tJKlXj246daZWQ/snKiEuWuWVdboy/bILvscwDDV4DN1w1QD16tFNPeIb/0fc6XQq/+BBDc/IuOBY22w2RUSE7rRYV+N0OpWfnx/w3x2+nuKTwjhM+XIKz5dTgQBgFnd9gzwtJ2UuyOVukLvekMvdoEh3Q7N99fUevZdfpnVbDyupe8v/iTzoOCWPYSg+9tyMfkWVq0O1X1jjtS++hiVJio1p+XFWU1evUUMuUb/eCRrct0er73M3eJTcK05jMpIVY4/sWLltiIyMUGSErfFPC18HhYsL2zCVmpoqSSopKZHb7W71dF9RUVGztgDgj6NllXKUXniW5ER5jU6dqb3oB/u6rYf9rKb4gnuPllW2ua89ASo2JlJXj+ir4+VOXTU82af3VNe4NTy1l5J6dFPPhAufGYiPtTcLd4AZwjZMjRgxQna7XS6XS3v37vUug3C+3bt3S5JGjx4d4uoAtOXNDz7Tc6/uV494304bdRa1rgaVnqg2uwyffWV0P40b1afF6/UNhlL79lDkeael7PYI9b0kvl2nRYCuJGzDVHx8vMaPH6/t27dr/fr1LcKUw+FQXl6eJCk7O9uMEgHL8XgM1dTVyzAMHS2rksc4dw6q6PMzutAZqb+8eURut0tJb1cpMrJxVmb/Jydls0lx3RpnHqrPu7381JnaoBxDKHxpyKUX3H+83Kmh/XuqZyun2s7XMyFGt00Y0q7vXeN06uChQ8pIT1dsK9eXREbYFB3g011AV9flw9SMGTNUVlam73znO8rJyWm2b+bMmdqxY4c2bdqkMWPGeJ/Nd+zYMc2ePVsej0eTJk3iUTJAKwzDUFNWevrF91VYcuaip7B8UVZe/oXv0zxENbnpmkG67ooUv79fqA3t39N7gbIZjIYoxdgj1C0mqtXrjAC0n2X+JZWWlmrKlCner5vutDt06JCuueYa7+v33nuv7rvvPu/XZWVlKi4uVmVly/P/mZmZmjNnjhYvXqz58+drxYoVSkpKUkFBgVwulwYPHqyFCxcG76AACzEMQ9t3f6a/7ipUyfEqVTrbvhP2fP16x599v1RyolpZX+rbaruGhgYddJzUf2ZnqEf3czMmhmFoUJ8e3rudYmOi1KtHNz+PBgACxzJhqqGhQeVf+D9WqXF9ifNfr61t39R/Tk6O0tPTtXLlSu3du1cnT55USkqKsrOzlZubq/j4eD8rB6ypqsatX6x5Vx9+fNzn9/zg9kxdmdZbvZPiFBFha3ZdzcU03d48fHgKSyMAsBTLhKn+/fvr0KFD7X7ftm3bLtomKytLWVlZHSkL6HIqqur06B/zVHC0vM02WV/qqxuuGqDL+/VUTHSkoqMaTxsBQDjitx8QxiqdLlVU1cnl9uhnv9+lSmfLW94zh16qyV8dooHJ3WWPitAlidZeNRsAAo0wBYSpJc/v1vbdn7W5f9iAnvqfH1zrvZMOANA6whTQBdW6Gh/aer7PTzpVfLxK2947qvfyy5rtS4i1q+rsHXOL7r9Owwf3svST6wEglAhTQBdx7JRTDy/bqZMV7bsJ49n/nqQ+l3CjBQB0FGEK6MQKPivXqbPhyFnrlqP0jOK62eWu9+iDw8eU3OvcXW9vfnDhx4Ocr/9lCframP6a8rWhAX8eGQCEG8IU0Em46z06XHRan35+Rg0Nhv7wykcXfc+hT0+3+vpT//VVDezTvdlrERE2Tt0BQBAQpgATHTvl1AeHj+mFLYcueHoubWBPSVKl063ucXYN6tND9Q0eSY0rajeJjLDp5msHexe4BAAEH2EKMMF7+WX6+R/zLtjmuitSdKqiVo/ff53sUcwoAUBnRZgCQuzWBze1eG1AcndVOl36yV1jlTn0UtlszCwBgFUQpoAg8XgMfVJSoYqqOv0971MVH69S0efNnxF561cu1z23jWrXY1cAAJ0LYQoIAl9O4730xC3qFs0/QQCwOn6TAwFUUVUnZ219iyAVFWlTbEyUrruin8ZnpuhLQy/lInEA6CIIU0AHudwN+ue7RfJ4DB1wnGp1naevXtlfP/nPsSZUBwAIFcIU0AHPbNir194uvGCbYQN66sG7xoSoIgCAWQhTQAd8MUhdl5miz09V66qMZH3rpnQWxwSAMEKYAtrBMAz96e8HvV8vf3iiBiR3v8A7AABdHWEK8NHmvCKtev1Qs9cIUgAAwhRwEYZh6IU3T+jQZ581e/2ZOTeYVBEAoDMhTAEXUOdu0Lfmb2322m8f/JoGpySaVBEAoLMhTAGtKD1RrQXPvqPSE9XNXv/dQ9drYJ8eJlUFAOiMCFPAedz1DVq0+l29l1/W7PXICOn/FkxSQkK8SZUBADorwhRw1vsHj2nBs+80e230sN760f83UkWOAlYsBwC0ijCFsFdV49aa1w9o8zuOZq+vnn+TLkmMldPpNKcwAIAlEKYQtsor6/SjX2/X6cq6Zq/nTvmSbv3K5SZVBQCwGsIUwtLHR09r9tNvNnvt0sRumnfPOF3ejzv1AAC+I0whrDhr3Zo+96/NXkvqHqNfzPqK+l7KxeUAgPYjTCFsfHj4mOY90/wC88kThujeyaNMqggA0BUQphAWbn1wU4vXXv3VbbLZuEMPAOAfwhS6rD2Hj2vfJyf14j+aP0/v3smjNHnCEJOqAgB0NYQpdCmGYeif7x7Vh4eP640PPmux/5Unb1Mk60UBAAKIMIUuo7WLyyXp+rH91e+yBE2flG5CVQCAro4whS6h7JRT9z7+j2avXTU8WdNvTFPGoF4mVQUACAeEKVje6TO1zYJU5tBL9fj915lYEQAgnESYXQDgr/ODVM/uMQQpAEBIEaZgea56j3f72UcmmVgJACAccZoPluXxGPrl/73n/fqx3Cx1i+FHGgAQWnzywJK2vVekp174oNlrmcN6m1QNACCccZoPlnO6srZFkFr8w/GsHwUAMAUzU7CUOneDvvPo371f/78ZYzTxqgEmVgQACHeEKXR6DR5DO3Yf1ZsfFOv9Q8e8r1+Z1psgBQAwHWEKndqrbx7Rs5v2tXh96ICeeuz715pQEQAAzRGm0Gn9+8DnLYLUqCGX6GtjBujr4waZVBUAAM0RptApHfz0lBY+9y/v1/fcNlKTJwyRzcZF5gCAzoUwhU6ltWfs3Td5lG6bMMSkigAAuDDCFDqFo2WVmvnLbS1enzYpjSAFAOjUCFPoFL4YpMZkXKb537tGkZEshQYA6NwIUzDds5s+8m6nD0zS4zOvU4w90sSKAADwHWEKptq4o0CvvvmJ9+tfPvAVRbCSOQDAQjiHAtN4PIZW/mW/9+v/+3k2QQoAYDmWm5nKy8vTqlWrtGfPHjmdTqWkpCg7O1u5ubmKi4trd3/l5eVatWqVduzYoaKiIrndbiUlJWn06NG66667NG7cuCAcBSRpwR/e8W4//O2rlJgQY2I1AAB0jKVmptauXaucnBzt2LFDMTExGjJkiIqLi7VixQrdcccdKi8vb1d/DodDt956q37/+9/r8OHDuuSSSzRs2DA5nU5t2bJFd999t5YvXx6cgwlj7nqPbn1wkz78+LgkqVePGF2bmWJyVQAAdIxlwtS+ffu0aNEiSdJjjz2mHTt2aOPGjdq6datGjhypI0eOaN68ee3qc8GCBTp27JhSU1P16quvauvWrdq4caPeeecdzZw5U5L029/+VgcPHgz48YQrl7tBt//0L81e++PcGxXJ6T0AgEVZJkwtX75cHo9HkydP1vTp070rYScnJ2vJkiWKiIjQli1bfA4+VVVV+te/GlfYfvjhhzVs2DDvvujoaP34xz/W8OHDZRiG3nzzzcAfUJi645HXmn294Re3yh7FnXsAAOuyRJiqrq7Wzp07JUnTpk1rsT81NdV7bdPmzZt96tPlcskwDEnSgAEDWm3T9Lrb7W53zWiusKRCL/3zsM4OuSTpz4u/IXuUJX4EAQBokyUuQM/Pz5fL5VJ0dLQyMzNbbTN27Fjt2rVLe/bs8anPXr16qW/fviotLdX777+vtLS0Zvvr6uq0b1/jQ3avuOIK/w4gzN0572+qdLqavfbMIzewlhQAoEuwxLRAYWGhJCklJUV2u73VNgMHDmzW1hcPPfSQbDabnnzySa1fv17Hjx9XTU2N9u3bp1mzZqmkpERf//rXNX78eP8PIkwdLatsFqS6x0Xr6+MGKeXSBBOrAgAgcCwxM1VRUSFJSkxMbLNN076mtr645ZZbFB8fr2XLlrW4eD0pKUnz58/XjBkzOlBxc4ZhyOl0+t3PF9XU1DT7szOa98wu7/aqudcrrlvjj1wwxiNYrDDOXQHjHBqMc+gw1qERrHE2DMN7ffbFWCJM1dXVSVKbs1JS40Xj57f1VVFRkSoqKmSz2dS3b1/16NFDRUVFOn36tNatW6cRI0boyiuv7HjxarzmKj8/368+LsThcAStb39U1zboZEWtJCm5p12fFn5sckX+6azj3NUwzqHBOIcOYx0awRjnpmxxMZYIUzExjYs5XuhCcJfL1aytL37+85/r+eefV0ZGhjZt2qT09HTv91m1apV+/etf6+6779YLL7ygkSNHdrh+u92uoUOHdvj9bampqZHD4VBqaqpiY2MD3r8/DMPQt+Zv9X796H3j1KtHNxMr6rjOPM5dCeMcGoxz6DDWoRGscS4oKPC5rSXClC+n8Hw5FXi+gwcP6oUXXlBUVJSWLl3qveZKagw/ubm5+uSTT7Rx40Y9/fTTevbZZztcv81m69Dq7L6KjY0Nav8dseDZd5p93b9PL5MqCZzOOM5dEeMcGoxz6DDWoRHocfb1FJ9kkQvQU1NTJUklJSVtzk4VFRU1a3sxu3fvlmEYGjRoULMgdb4JEyZIkvbu3du+gqH3Dx7zbj/735NMrAQAgOCyRJgaMWKE7Ha7XC5Xm8Fm9+7dkqTRo0f71Gd1dbUk35Jn0ylEXNzhotOa+vCr3q9n3zlGfS6JN7EiAACCyxJhKj4+3rs8wfr161vsdzgcysvLkyRlZ2f71OfgwYO97z169GirbZoWCm1qiwtb+7d8PfibN1XfcG5lzi8PTzaxIgAAgs8SYUqSZs6cKZvNpk2bNmndunXe1cuPHTum2bNny+PxaNKkScrIyGj2vhkzZmjixIlavXp1s9fHjx+vSy+9VPX19frRj36kjz8+d6eZ2+3WH//4R23YsEGSNGXKlKAeW1fgrHVr/dbD3q/jukXpqf/3VSXE+XYnBAAAVmWJC9AlKTMzU3PmzNHixYs1f/58rVixQklJSSooKJDL5dLgwYO1cOHCFu8rKytTcXGxKisrm70eGxurX/3qV5o5c6YOHDigW2+9VSkpKd6lEZpOA95000266667QnKMVtXgMTR97l+9X/88N0tj0i8zsSIAAELHMmFKknJycpSenq6VK1dq7969OnnypFJSUpSdna3c3FzFx7fv2pysrCy99tprWrNmjXbt2qXPPvtMZWVlSkxM1JgxYzR16lTdcsstQTqarmPKQ682+5ogBQAIJ5YKU1JjAMrKyvK5/bZt2y64v1+/fvrv//5vf8sKSx6PoV+ufa/Za6/+6jaTqgEAwByWC1PoHBo8RosZqY2/vLVd63IAANAVWOYCdHQu836/q9nXz829UVGR/DgBAMIPM1PoELv9XHD6y68nm1gJAADmYioBHVJY3Pj4ngfvGmtyJQAAmIuZKbRLdY1b9y3aqkpn46rwkVwjBQAIc8xMoV3W/PWAN0hJ0tjhLIMAAAhvzEyhXf62y+HdfnnxNxRtjzSvGAAAOgFmpuCzkxU13u37Jo8iSAEAIMIU2mH16we827d+5XITKwEAoPMgTMEn7+WXacfuzyRJPeKjWZwTAICzCFPwyZrzZqVYDgEAgHMIU/BJYkK0JOm2CZfzIGMAAM5DmIJP6hsMSdKI1EtMrgQAgM6FMAWf7P/kpCTJHsWPDAAA5+OTET6JOHu9eVw3liYDAOB8hClclLPWLU/jWT4NSO5ubjEAAHQyhClc1N0//7t3OzaGmSkAAM5HmMIF3TX/b6p1NXi/ZtVzAACaI0yhTbWuep2pPvdQ4xU/nWhiNQAAdE6cs0GbHKVnvNsbf3mroiLJ3gAAfBGfjmjT6TN13m2CFAAAreMTEq1qaPBo0ep/S5L6XhJvcjUAAHRehCm06uXtBd7t9EFJJlYCAEDnRphCq44Ul3u3ebAxAABtI0yhhR27j2rX3lJJ0rRJaSZXAwBA50aYQgv7C095t8dmXGZiJQAAdH6EKbTwxvtHJUl33zJCIwZfYnI1AAB0boQpNGMYhmrqGlc8T4i1m1wNAACdH2EKzbz0z4+926OGMCsFAMDFEKbgZRiG1v4t3/t1/8u6m1gNAADWQJiC18dHy73b8++5xrxCAACwEMIUvPId5+7i+/KIPiZWAgCAdRCm4GUYjX/y+BgAAHxHmILXc6/uk8SF5wAAtAdhCpKk/PMW6oyJjjSxEgAArIUwBbnrPXp42U7v19/9xkgTqwEAwFoIU9BL/zzs3b7x6oGKtjMzBQCArwhTkKfpynNJD0wbbV4hAABYEGEqzNU3eLTuH40zU/9xbapsNpvJFQEAYC2EqTC378gJ73ZCXLSJlQAAYE2EqTD36eeV3u3/zM4wsRIAAKyJMBXm/ripcW2pIf0TOcUHAEAHEKbC2OGi097tLw/n8TEAAHQEYSqMvfiPQ97taZPSTKwEAADrIkyFscLiCknSVcOTZY/iRwEAgI7gEzRMnT5TqxMVtZKkEYN7mVwNAADWRZgKU9/5+d+9218bM8DESgAAsDbCVBgyzlvxPD7Wrt5JsSZWAwCAtRGmwtBL//zYu730wetNrAQAAOuLMruA9srLy9OqVau0Z88eOZ1OpaSkKDs7W7m5uYqLi+twv2+88YZeeuklffjhhyovL1ePHj00cOBAXXPNNXrggQcUFWW5oWrT1neLvNvMSgEA4B9LzUytXbtWOTk52rFjh2JiYjRkyBAVFxdrxYoVuuOOO1ReXt7uPuvr6/XQQw8pNzdX//jHPxQZGamMjAzFxcVp3759+v3vf6+6urrAH4yJ+l4aL0maPGGIyZUAAGB9lplu2bdvnxYtWiRJeuyxxzRt2jTZbDaVlZXp/vvv1/79+zVv3jwtXbq0Xf0++uijevXVV5WRkaGFCxcqMzPTu6+mpka7du1SdHTXemZdfb1HkpQ2sKe5hQAA0AVYZmZq+fLl8ng8mjx5sqZPn+599ElycrKWLFmiiIgIbdmyRQcPHvS5z7y8PL300ku67LLLtGbNmmZBSpJiY2N1ww03yG63B/RYzLa3oPHhxlGRlvnrBwCg07LEp2l1dbV27twpSZo2bVqL/ampqRo3bpwkafPmzT73u3r1aknSPffco549e/pdp1VEnH0EX7cYy0xMAgDQaVni0zQ/P18ul0vR0dEtZo+ajB07Vrt27dKePXt86rOurk5vvfWWJOmGG27Q3r17tWHDBn366aeKiYnRqFGjdMcdd6hPn671zLqqGrc8Z1dG6NOr4xfsAwCARpYIU4WFhZKklJSUNk+5DRw4sFnbizl48KDcbrfi4uL097//Xb/+9a/l8Xi8+7dv365nn31Wixcv1s033+znEXQex087vdvJl8SbWAkAAF2DJcJURUXjM+QSExPbbNO0r6ntxRw/flyS5HK59OSTT2rs2LGaO3euhg0bppKSEj311FPavHmzHnroIQ0ePFgZGRkdrt8wDDmdzos3bKeamppmf/qitrbxETKJCdGqq/X9feGsI+OM9mOcQ4NxDh3GOjSCNc6GYXivz74YS4SppqUJLnQheNMdd74uY1BdXS2pcWmEpKQk/eEPf1BCQoKkxmuwnnrqKX366afKz8/XihUr9Jvf/KbD9bvdbuXn53f4/RfjcDh8bpt/tPGHrb6+Pqg1dUXtGWd0HOMcGoxz6DDWoRGMcfb1bn5LhKmYmBhJjaGkLS6Xq1lbX/uUpOnTp3uDVJOIiAjl5OTopz/9qd566y15PB5FRHTsen273a6hQ4d26L0XUlNTI4fDodTUVMXG+rb45ruOQ5JOqrrWo+HDhwe8pq6oI+OM9mOcQ4NxDh3GOjSCNc4FBQU+t7VEmPLlFJ4vpwJb61OSLr/88lbbNL1eVVWl8vJy9erVy6e+v8hms/m1OvvFxMbG+tz/67saVz8fPax3UGvqitozzug4xjk0GOfQYaxDI9Dj7OspPskiSyOkpqZKkkpKStqcnSoqKmrW9mLOD1BtzWad//r5F6db1Zlql3c7fVCSiZUAANB1WCJMjRgxQna7XS6XS3v37m21ze7duyVJo0eP9qnP5ORk9evXT9K5IPZFR48eldR4zrQrrENVdqrau/2tm9JNrAQAgK7DEmEqPj5e48ePlyStX7++xX6Hw6G8vDxJUnZ2ts/9Ni158Morr7Q68/TnP/9ZknT11Vd3iQcdv3/omHeb1c8BAAgMy3yizpw5UzabTZs2bdK6detkGI0rTx47dkyzZ8+Wx+PRpEmTWixhMGPGDE2cONG72vn57rnnHnXv3l1HjhzRokWLvBexG4ahNWvWaPv27bLZbMrNzQ368YVCxNnzv5ckdjO5EgAAug7LTLdkZmZqzpw5Wrx4sebPn68VK1YoKSlJBQUFcrlcGjx4sBYuXNjifWVlZSouLlZlZWWLfb169dJvf/tb3X///Vq7dq1effVVDRo0SKWlpTp+/LhsNpseeughXXPNNaE4xJAZk36Z2SUAANBlWGZmSpJycnK0atUqTZgwQTU1NSooKFBKSop+8IMf6OWXX+7Q3XbXXnutNm3apNtvv12xsbHKz89XfX29Jk6cqP/93//VPffcE4QjMcfug8cu3ggAALSLZWammmRlZSkrK8vn9tu2bbtom9TUVD3xxBP+lGUJiQmNi4/V1NWbXAkAAF2HpWam4J/3z85MjU7jNB8AAIES0jDVdIE3zFHrapAkxdjJ0AAABEpIPlXr6+v1pz/9STfeeGMovh0uou+l8WaXAABAlxHUa6Y8Ho9efvllrVixQqWlpcH8VriIpqUkJKl3Eo81AAAgUNodphwOhzZu3KiCggI1NDRowIABuv3221s8NPevf/2rnn76aR09etT7Qf61r30tIEWj/ba9d9S7HW2PNLESAAC6lnaFqZdfflkLFixQQ0NDs9f/7//+Tz/96U+Vk5Oj48eP6yc/+Yn+/e9/yzAMRURE6KabbtIPfvCDFoELofPWnhLvdnw3y93ECQBAp+Xzp+qRI0e0YMEC1dc33lYfGxsrSaqpqZEk/eIXv9Do0aM1Z84cORwORUVF6dZbb1Vubq4GDx4chNLhK8Mw9F5+mSQp60t92/UkbAAAcGE+h6k//elPqq+vV0pKin75y1/qqquukiS9++67evjhh1VaWqrvf//7qqioUFZWlh599FENGjQoaIXDdx8cOu7dHjeqr4mVAADQ9fh8N997770nm82mn/3sZ94gJUlf/vKXNXfuXEnSmTNnNHHiRK1cuZIg1YlU17i92xOvGmBiJQAAdD0+h6ni4mLZbDZ95StfabFvwoQJ3lNHTQ8kRufhbvBI4pl8AAAEg89hyul0qmfPnrLb7S32RUdHq2fPnpKkYcOGBaw4BMbRssaHPEdGEnIBAAg0n8NU0515bYmMbLzdPiYmxv+qEFCVzsaV50+fqTW5EgAAuh6eKxIG9h05IUkaNiDJ5EoAAOh62rXgkNPp1LJly1rdV11dLUlt7m8ya9as9nxLBMCpM3WSJDvP5AMAIODaFaZqamr0u9/97oJtLrafMBVahSUVqqlrXBvsyjQuQAcAINDaFabOf74brGHd1sPe7SuGXWpiJQAAdE0+h6mDBw8Gsw4ESczZ5/CNGnKJ7FE8kw8AgEDjIpou7l/7SiVJ12WmmFwJAABdE2GqC3PWulVd23i9VHxsy/XBAACA/9p1zZQkuVwu/fOf/9RHH32kqqoq9ezZU1dccYWuv/76C65DhdA7UHjKu53FM/kAAAiKdoWp/fv364EHHlBpaWmLfampqVqxYoVSU1MDVRv8tH33Ue92t5h252YAAOADn6eSTp8+rdzcXJWWlsowjBb/FRYWKjc3V7W1rLLdWTSd2uudFGtyJQAAdF0+h6nnn39eJ0+eVFRUlO6//35t3rxZH374oV5//XXdeeedioiI0NGjR7Vp06Zg1ot2cLsbH3B8c1aquYUAANCF+Rymdu7cKZvNplmzZunHP/6xUlNT1a1bNw0ZMkTz58/XnXfeKcMw9OabbwazXrTDh4ePSZLsUVzLBgBAsPj8KVtYWChJuvPOO1vdP2PGDEmSw+HwvyoEhOfsGqsej7l1AADQlfkcpiorK9WjRw9179691f0DBw6UJFVVVQWmMvjFWevWqTON16+NvLyXydUAANB1+RymPB6P7Pa21ypq2tfQ0OB/VfDbc6/u925f3i/RxEoAAOjauJimi4qJPvfoGB4jAwBA8LRr8aG6ujq98sorfrWZMmVKe74lOqjS6ZIk3fn1DJMrAQCga2tXmKqqqtIjjzzS5n6bzXbBNjabjTAVIjt2fyZJioq0mVwJAABdW7vClGEYwaoDAdTQcO72vUt7smAnAADB5HOY+uc//xnMOhBAn35e6d0ef0WKiZUAAND1+Rym+vXrF8w6EECu+nN3VHLxOQAAweXz3XyvvPKK/va3vwWzFgRIQ0Pj6diUS+NNrgQAgK7P55mpOXPmqHfv3rr55puDWQ8CoM7dODMVGcnKFwAABFu7Pm25AN0ayk45JZ0LVQAAIHiYuuiC7GdnpDwewi8AAMFGmOqC6s8ujTCEx8gAABB0hKkuxjAM/fHVfZKkSBbsBAAg6AhTXczGHUdU52q8Vqrprj4AABA87VoB/eTJkxo+fHiHv5nNZtOBAwc6/H5c3CtvFHi37/9mpomVAAAQHtoVpiTu6OvsEhNidLqyTtMnpemSRB4lAwBAsLUrTMXGxup73/tesGqBnwzDkKP0jCRpbEayydUAABAe2hWm4uLiNGvWrGDVAj9V19Z7t/uy+jkAACHBBehdyOkztd7txIRoEysBACB8EKa6kNIT1d5tm41lEQAACAXCVBfiPrtY5+Us1gkAQMgQprqQo2WVkqSEWLvJlQAAED4IU11IpdMlSTpdWXuRlgAAIFB8vpvv4MGDwazDZ3l5eVq1apX27Nkjp9OplJQUZWdnKzc3V3FxcX73/8Ybbyg3N1eS1K9fP23bts3vPkMl4ux1UiMGX2JyJQAAhA9LzUytXbtWOTk52rFjh2JiYjRkyBAVFxdrxYoVuuOOO1ReXu5X/1VVVVqwYEFgijWBx9O4oGqPeO7kAwAgVCwTpvbt26dFixZJkh577DHt2LFDGzdu1NatWzVy5EgdOXJE8+bN8+t7/OpXv1JpaakmTZoUiJJDruFsmIqI4E4+AABCxTJhavny5fJ4PJo8ebKmT5/uvfU/OTlZS5YsUUREhLZs2dLh05HvvfeeXnzxRd1444264YYbAll6yDhr3ZKkyAjL/LUCAGB5lvjUra6u1s6dOyVJ06ZNa7E/NTVV48aNkyRt3ry53f3X1dXpZz/7meLi4vye3TLT9t2fSeL5iQAAhJIlwlR+fr5cLpeio6OVmZnZapuxY8dKkvbs2dPu/n/3u9+psLBQs2fPVnKy9Z9pl5gQY3YJAACEDUuEqcLCQklSSkqK7PbW11AaOHBgs7a+ys/P13PPPafMzEzdeeed/hVqooazC3ZK0tiMy0ysBACA8NKuBx2bpaKiQpKUmNj2yt5N+5ra+qKhoUFz586VJC1cuFARQbrWyDAMOZ3OgPdbU1Pj/bPO1eB9PTqiISjfL1ydP84IHsY5NBjn0GGsQyNY42wYhs+PZrNEmKqrq5OkNmelJCk6OrpZW18899xz2r9/v+69915lZGT4V+QFuN1u5efnB61/h8OhGte5mamPPz6sqEju6As0h8NhdglhgXEODcY5dBjr0AjGODdli4uxRJiKiWm8BsjtdrfZxuVyNWt7MQ6HQ8uWLVP//v01a9Ys/4u8ALvdrqFDhwa835qaGjkcDqWmpup0lUdSiSRp1MjhPOg4gM4f59jYWLPL6bIY59BgnEOHsQ6NYI1zQUGBz20tEaZ8OYXny6nA8y1YsEB1dXV69NFHg/5DbrPZArI6e1tiY2M1c8l279fx8fFB+17hLDY2Nqh/j2jEOIcG4xw6jHVoBHqc2zMpYYkwlZqaKkkqKSmR2+1u9XRfUVFRs7YXs3//ftlsNs2ZM6fFvtraxmfblZaW6rrrrpMkLV26VGPGjOlA9aERY4+Us7Ze3eNY/RwAgFCyRJgaMWKE7Ha7XC6X9u7d610G4Xy7d++WJI0ePdrnfg3D0IkTJ9rc7/F4vPsvdIqxMzhd2Xit2P/84FqTKwEAILxYIkzFx8dr/Pjx2r59u9avX98iTDkcDuXl5UmSsrOzferzvffea3Pfhg0b9Mgjj1jmQcefHavybjMzBQBAaFlinSlJmjlzpmw2mzZt2qR169Z5V/k+duyYZs+eLY/Ho0mTJrW4K2/GjBmaOHGiVq9ebULVofHZsWrv9qU9u5lYCQAA4ccyYSozM9N7fdP8+fN1/fXXa+rUqbrhhhu0f/9+DR48WAsXLmzxvrKyMhUXF6uysjLUJYfM4aPlkqTRab25iw8AgBCzxGm+Jjk5OUpPT9fKlSu1d+9enTx5UikpKcrOzlZubm7Y3sV2vLzxgvkzVS6TKwEAIPxYKkxJUlZWlrKysnxu35Frnm6//Xbdfvvt7X6fWY6dblz1ddSQS0yuBACA8GOZ03xo2+cnGx8dk9I7weRKAAAIP4SpLiA2pnGCcVCf7iZXAgBA+CFMdQFNa0wlJvj2KB0AABA4hCmLq28wvNvxsW0/CBoAAAQHYcriGjznwlRcN8vdTwAAgOURpizuvCylyAj+OgEACDU+fS2uaSV4SYqIYMFOAABCjTBlcR7PuW2yFAAAoUeYsriq2gZJjbNSPEoGAIDQI0xZXPFJtyTJc/7FUwAAIGQIUxYXFdn4ZyTn+AAAMAVhyuKarj+/Iq23uYUAABCmCFMW13R2L4LrpQAAMAVhyuI8Z6emOM0HAIA5CFMW13SajzWmAAAwB2HK4sqr6iVxmg8AALMQpiyu6ZqpU2dqzS0EAIAwRZiyuKZrpVJ6x5tcCQAA4YkwZXFNF6D3iI8xuRIAAMITYcrimp7Nx918AACYgzBlcR7u5gMAwFSEKYv7uKRGEjNTAACYhTBlcd1jGx/OV13jNrkSAADCE2HK4pqWlxo+uJe5hQAAEKYIUwAAAH4gTAEAAPiBMAUAAOAHwhQAAIAfCFMAAAB+IEwBAAD4gTAFAADgB8IUAACAHwhTAAAAfiBMAQAA+IEwBQAA4AfCFAAAgB8IUwAAAH4gTAEAAPiBMAUAAOAHwhQAAIAfCFMAAAB+IEwBAAD4gTAFAADgB8KUxR2rqDe7BAAAwhphyuJq6jySpPp6j8mVAAAQnghTFhcX0/hX2O+yBJMrAQAgPBGmuojoqEizSwAAICwRpgAAAPxAmAIAAPADYQoAAMAPUWYX0F55eXlatWqV9uzZI6fTqZSUFGVnZys3N1dxcXE+92MYhj744ANt27ZNu3fv1ieffKKqqip1795dI0aM0JQpU3TrrbfKZrMF8WgAAIDVWSpMrV27Vo8//rgMw1CfPn3Ut29fFRQUaMWKFdqyZYuef/559ezZ06e+8vLylJOT4/16wIAB6tevn4qLi/X222/r7bff1uuvv66lS5cqOjo6OAcEAAAszzKn+fbt26dFixZJkh577DHt2LFDGzdu1NatWzVy5EgdOXJE8+bN87k/wzDUv39/zZ07V7t27dLWrVu1YcMG/etf/9IvfvELRUdHa8eOHfrtb38brEMKCGcd60sBAGAmy4Sp5cuXy+PxaPLkyZo+fbr39FtycrKWLFmiiIgIbdmyRQcPHvSpv8zMTG3evFnf+c53dMkllzTbN2XKFP3whz+UJL300kvyeDpnYKmtO7f6eUw0SyMAAGAGS4Sp6upq7dy5U5I0bdq0FvtTU1M1btw4SdLmzZt96jMhIUF2u73N/RMmTJAklZeX69SpU+0tOSTcDedCXu8k368XAwAAgWOJMJWfny+Xy6Xo6GhlZma22mbs2LGSpD179gTke9bV1Xm3u3XrFpA+AQBA12OJC9ALCwslSSkpKW3OJg0cOLBZW3+9/vrrkqSMjAwlJPj3qBbDMOR0OgNRVjO1NbXe7RqnUxER3HkYDDU1Nc3+RHAwzqHBOIcOYx0awRpnwzB8vqPfEmGqoqJCkpSYmNhmm6Z9TW39sX//fr344ouSpNzcXL/7c7vdys/P97ufL3LWNXi38/PzCVNB5nA4zC4hLDDOocE4hw5jHRrBGGdf7+a3RJhqOuV2oWucmg74/NNzHXHixAnNmjVLbrdbN954o2655Ra/+pMa6x46dKjf/XzR8ZNnJJVKkoYPH06YCpKamho5HA6lpqYqNjbW7HK6LMY5NBjn0GGsQyNY41xQUOBzW0uEqZiYGEmNMzxtcblczdp2RGVlpe677z6VlJRo5MiRWrx4cYf7Op/NZmvXgqK+qj9Z7d2OjYtTJGEqqGJjY4Py94jmGOfQYJxDh7EOjUCPc3sW7bbEBei+nMLz5VTghVRXV+vee+/VgQMHNGzYMD333HN+XysVbKcrXd5tchQAAOawRJhKTU2VJJWUlLQ5O1VUVNSsbXvU1NTo+9//vj788EOlpqZq1apVSkpK6mi5oWMYkqSUS+N47A0AACaxRJgaMWKE7Ha7XC6X9u7d22qb3bt3S5JGjx7drr7r6uo0c+ZMvfvuu+rXr5/WrFmj3r17+1tySBjeLYIUAABmsUSYio+P1/jx4yVJ69evb7Hf4XAoLy9PkpSdne1zv263Ww888IB27dqlPn36aM2aNerTp09gig6BsxNTYlIKAADzWCJMSdLMmTNls9m0adMmrVu3TsbZJHHs2DHNnj1bHo9HkyZNUkZGRrP3zZgxQxMnTtTq1aubvd7Q0KCf/OQneuONN9S7d2+tWbNGAwYMCNXhBBRZCgAA81jibj6p8Vl6c+bM0eLFizV//nytWLFCSUlJKigokMvl0uDBg7Vw4cIW7ysrK1NxcbEqKyubvf63v/3N++iZ6OhoPfLII21+73nz5mnEiBGBPaAAMLxTU+bWAQBAOLNMmJKknJwcpaena+XKldq7d69OnjyplJQUZWdnKzc3V/Hx8T731bSUgiQVFxeruLi4zbZfDGKdRdM1UzbSFAAAprFUmJKkrKwsZWVl+dx+27Ztrb5+++236/bbbw9UWebgmikAAExnmWum0JJx8SYAACDICFMW1nTNFDNTAACYhzDVBXDNFAAA5iFMWZhx7gp0AABgEsKUpXGaDwAAsxGmLIxlpgAAMB9hysK8d/MxNQUAgGkIU1bGzBQAAKYjTFkYSyMAAGA+wpSFnVu0kzQFAIBZCFNWxuNkAAAwHWHKwlhmCgAA8xGmLOzw0XJJkoeH9AEAYBrClIXFd7NLkk5X1plcCQAA4Ysw1QVcMfQSs0sAACBsEaYAAAD8QJgCAADwA2EKAADAD4QpC3txa4EkyRC38wEAYBbClIX17x0vSSo7WWNyJQAAhC/ClIXZ7Y1/fd8YP8jkSgAACF+EqS4ggufJAABgGsIUAACAHwhTAAAAfiBMAQAA+IEwBQAA4AfCFAAAgB8IUwAAAH4gTAEAAPiBMAUAAOAHwhQAAIAfCFMAAAB+IEwBAAD4gTAFAADgB8IUAACAHwhTAAAAfiBMAQAA+IEwBQAA4AfCFAAAgB8IUxbW0GCYXQIAAGGPMGVhRWVVkiTDIFQBAGAWwpSFXdIjRpIUbY80uRIAAMIXYcrCmuaj4rpFmVoHAADhjDBlYU2n9yJsNpMrAQAgfBGmLIxLpQAAMB9hysKashQTUwAAmIcwZWFNp/lspCkAAExDmLKwptN8RCkAAMxDmLIwb5giTQEAYBrL3VOfl5enVatWac+ePXI6nUpJSVF2drZyc3MVFxfXafoMBUOc5gMAwGyWmplau3atcnJytGPHDsXExGjIkCEqLi7WihUrdMcdd6i8vLxT9BkqnOYDAMB8lglT+/bt06JFiyRJjz32mHbs2KGNGzdq69atGjlypI4cOaJ58+aZ3mcoecOUZf4WAQDoeizzMbx8+XJ5PB5NnjxZ06dP957aSk5O1pIlSxQREaEtW7bo4MGDpvYZWmdP8zE3BQCAaSwRpqqrq7Vz505J0rRp01rsT01N1bhx4yRJmzdvNq3PUPN4F5oytQwAAMKaJcJUfn6+XC6XoqOjlZmZ2WqbsWPHSpL27NljWp+hVudqkMTjZAAAMJMl7uYrLCyUJKWkpMhut7faZuDAgc3amtFnWwzDkNPp9KuPL6pyur3bDfWugPePc2pqapr9ieBgnEODcQ4dxjo0gjXOhmH4fLe8JcJURUWFJCkxMbHNNk37mtqa0Wdb3G638vPz/erji5x1Dd7t8hMlKj9REtD+0ZLD4TC7hLDAOIcG4xw6jHVoBGOco6OjfWpniTBVV1cnSW3OIEnnDriprRl9tsVut2vo0KF+9dGa/4pIUmXFcaWmpio2Njbg/aNRTU2NHA4H4xxkjHNoMM6hw1iHRrDGuaCgwOe2lghTMTExkhpneNricrmatTWjz7bYbLagLP6ZldlP+flnFBsb26kXF+0qGOfQYJxDg3EOHcY6NAI9zu1ZENsSF6D7crrNl9N2we4TAACEH0uEqdTUVElSSUlJmzNJRUVFzdqa0ScAAAg/lghTI0aMkN1ul8vl0t69e1tts3v3bknS6NGjTesTAACEH0uEqfj4eI0fP16StH79+hb7HQ6H8vLyJEnZ2dmm9QkAAMKPJcKUJM2cOVM2m02bNm3SunXrZJx9MN2xY8c0e/ZseTweTZo0SRkZGc3eN2PGDE2cOFGrV68OWJ8AAABNLBOmMjMzNWfOHEnS/Pnzdf3112vq1Km64YYbtH//fg0ePFgLFy5s8b6ysjIVFxersrIyYH0CAAA0scTSCE1ycnKUnp6ulStXau/evTp58qRSUlKUnZ2t3NxcxcfHd4o+AQBA+LBUmJKkrKwsZWVl+dx+27ZtAe8TAACgiWVO8wEAAHRGhCkAAAA/EKYAAAD8QJgCAADwA2EKAADADzajaaVKBMX7778vwzAUHR0d8L4Nw5Db7Zbdbm/X063RPoxzaDDOocE4hw5jHRrBGmeXyyWbzaYxY8ZctK3llkawmmD+A7LZbEEJaWiOcQ4Nxjk0GOfQYaxDI1jjbLPZfP4MZ2YKAADAD1wzBQAA4AfCFAAAgB8IUwAAAH4gTAEAAPiBMAUAAOAHwhQAAIAfCFMAAAB+IEwBAAD4gTAFAADgB8IUAACAHwhTAAAAfiBMAQAA+IEwBQAA4IcoswtAo7y8PK1atUp79uyR0+lUSkqKsrOzlZubq7i4uE7Tp9UFakwMw9AHH3ygbdu2affu3frkk09UVVWl7t27a8SIEZoyZYpuvfVW2Wy2IB5N5xXsn7033nhDubm5kqR+/fpp27ZtfvdpVcEa6zfeeEMvvfSSPvzwQ5WXl6tHjx4aOHCgrrnmGj3wwAOKigqvj49Aj3N5eblWrVqlHTt2qKioSG63W0lJSRo9erTuuusujRs3LghH0XkdP35cu3bt0kcffaR9+/YpPz9ftbW1GjlypDZs2OBX36H4LLQZhmEEpCd02Nq1a/X444/LMAz16dNHvXr1UkFBgVwul4YMGaLnn39ePXv2NL1PqwvkmLzzzjvKycnxfj1gwAD16NFDxcXFKi8vlyR97Wtf09KlSxUdHR34g+nEgv2zV1VVpW984xsqLS2VFN5hKhhjXV9fr0ceeUSvvvqqJKlPnz7q3bu3ysvL9fnnn8vtduv9999XfHx8EI6ocwr0ODscDn3729/WsWPHFBERoX79+ql79+4qKipSVVWVJOnHP/6xZs6cGaQj6nxWr16tJ554osXr/oapkH0WGjDVRx99ZGRkZBjp6enGiy++aHg8HsMwDOPzzz83pk6daqSlpRmzZs0yvU+rC/SYvP3228bEiRONNWvWGCdOnGi2b+PGjcaoUaOMtLQ048knnwzocXR2ofjZW7BggZGWlmbMnDnTSEtLM66//vpAlG45wRrruXPnGmlpacZtt91m7Nmzp9k+p9NpbN261XC5XAE5BisIxjh/5zvfMdLS0oybbrrJOHz4sPf1uro64+mnnzbS0tKM9PR0Iz8/P6DH0pm99NJLRk5OjvGrX/3K2Lx5s/H73//eSEtLM6ZOndrhPkP5WUiYMtn9999vpKWlGQ8//HCLfYWFhUZGRoaRlpbWrn9UwejT6gI9JpWVlRf8QFmxYoWRlpZmXH311UZDQ0OH67aaYP/svfvuu0Z6errxwx/+0Hj55ZfDOkwFY6zfeecdIy0tzRg/frxx+vTpAFZrXcH43ZGenm6kpaUZW7dubbXN5MmTjbS0NOOZZ57xq3Yra/r37U+YCuVnIRegm6i6ulo7d+6UJE2bNq3F/tTUVO95882bN5vWp9UFY0wSEhJkt9vb3D9hwgRJjddFnDp1qr0lW1Kwf/bq6ur0s5/9THFxcZo3b55/xVpcsMZ69erVkqR77rkn7C4DaE0wxtnlcsk4e3XNgAEDWm3T9Lrb7W53zWgU6s9CwpSJ8vPz5XK5FB0drczMzFbbjB07VpK0Z88e0/q0OjPGpK6uzrvdrVu3gPTZ2QV7nH/3u9+psLBQs2fPVnJysl+1Wl0wxrqurk5vvfWWJOmGG27Q3r179eijj+q73/2ufvCDH2jZsmX6/PPPA3MAFhGMce7Vq5f69u0rSXr//fdb7K+rq9O+ffskSVdccUVHyoZC/3s/vG7H6GQKCwslSSkpKW3OcgwcOLBZWzP6tDozxuT111+XJGVkZCghISEgfXZ2wRzn/Px8Pffcc8rMzNSdd97pX6FdQDDG+uDBg3K73YqLi9Pf//53/frXv5bH4/Hu3759u5599lktXrxYN998s59HYA3B+pl+6KGH9OCDD+rJJ59URESErr/+eiUkJOjIkSP6zW9+o5KSEn3961/X+PHj/T+IMBXq3/uEKRNVVFRIkhITE9ts07Svqa0ZfVpdqMdk//79evHFFyXJe/t+OAjWODc0NGju3LmSpIULFyoiggn1YIz18ePHJTWehnryySc1duxYzZ07V8OGDVNJSYmeeuopbd68WQ899JAGDx6sjIwMP4+i8wvWz/Qtt9yi+Ph4LVu2rMUp66SkJM2fP18zZszoQMVoEurf+/xWMlHTqaALXXvTdFv9+aeNQt2n1YVyTE6cOKFZs2bJ7Xbrxhtv1C233OJXf1YSrHF+7rnntH//fuXk5ITFB7gvgjHW1dXVkhqXRkhKStIf/vAHjRw5UtHR0UpNTdVTTz2l4cOHy+12a8WKFX4egTUE83dHUVGRKioqZLPZlJKSooyMDMXFxen06dNat25d2FyGESyh/iwkTJkoJiZG0oUvMnS5XM3amtGn1YVqTCorK3XfffeppKREI0eO1OLFizvclxUFY5wdDoeWLVum/v37a9asWf4X2UUE83eHJE2fPr3F6emIiAjv2mpvvfVWs1OAXVWwfnf8/Oc/1+OPP664uDht2rRJ27dv16ZNm/Tvf/9bDz74oA4dOqS7775b+/fv9+8AwlioPwsJUybyZYrRl6nKYPdpdaEYk+rqat177706cOCAhg0bpueeey5srpVqEoxxXrBggerq6vToo48qNjbW/yK7iGD+7pCkyy+/vNU2Ta9XVVV5F6ftyoIxzgcPHtQLL7ygqKgoLV26VOnp6d59drtdubm5mjp1qurq6vT00093vPgwF+rPQq6ZMlFqaqokqaSkRG63u9XpyKKiomZtzejT6oI9JjU1Nfr+97+vDz/8UKmpqVq1apWSkpL8KdmSgjHO+/fvl81m05w5c1rsq62tlSSVlpbquuuukyQtXbpUY8aM6UD11hKMsT4/QLX1f+rnvx4OM1PBGOfdu3fLMAwNGjTIewH0F02YMEEbN27U3r17O1Q3Qv9ZyMyUiUaMGCG73S6Xy9XmP5rdu3dLkkaPHm1an1YXzDGpq6vTzJkz9e6776pfv35as2aNevfu7W/JlhSscTYMQydOnGjxX9NjNzwej/e1cFmXJxhjnZycrH79+kk69yHzRUePHpXUeK1JOKxDFYxxbro2zZfndjadhkL7hfqzkDBlovj4eO+tr+vXr2+x3+FwKC8vT5KUnZ1tWp9WF6wxcbvdeuCBB7Rr1y716dNHa9asUZ8+fQJTtAUFY5zfe+89HTp0qNX/mp7j1a9fP+9r11xzTYCOpnML1s9005IHr7zySqszT3/+858lSVdffXVYPOg4GOM8ePBg73ubwukXNS022dQW7Rfqz0LClMlmzpwpm82mTZs2ad26dd6VcY8dO6bZs2fL4/Fo0qRJLe5imjFjhiZOnOhdsTgQfXZlgR7nhoYG/eQnP9Ebb7yh3r17a82aNW2uZhxOgvHzjNYFY6zvuecede/eXUeOHNGiRYu8MyOGYWjNmjXavn27bDZbWC35EehxHj9+vC699FLV19frRz/6kT7++GPvPrfbrT/+8Y/eB/tOmTIlqMfWFXSWz0Kb0dQ7TLN69WotXrxYhmGob9++SkpK8j7VevDgwXr++efVq1evZu+ZOHGiiouLNWvWLD3wwAMB6bOrC+Q4v/baa3rwwQclNc6MXGhF7nnz5mnEiBHBOahOKBg/z63ZsGGDHnnkEfXr10/btm0LxqF0esEY6127dun+++9XbW2tEhMTNWjQIJWWlur48eOy2Wx66KGHdM8994TqEDuFQI/zO++8o5kzZ8rpdHqXRujRo4eKioq8pwFvuukmPf3004qMjAzZcZqptLS0WXh0uVxyOp2KiopqdjPPvffeq/vuu8/7dWf5LOz687QWkJOTo/T0dK1cuVJ79+7VyZMnlZKSouzsbOXm5io+Pr5T9Gl1gRyT869lKC4uVnFxcZttKysr/arbavjZC51gjPW1116rTZs26ZlnntGuXbuUn5+vhIQETZw4Ud/97nd19dVXB+FIOrdAj3NWVpZee+01rVmzRrt27dJnn32msrIyJSYmasyYMZo6dWpYrVEnNc72t3aHaH19fbPXm2488VWofh8xMwUAAOAHrpkCAADwA2EKAADAD4QpAAAAPxCmAAAA/ECYAgAA8ANhCgAAwA+EKQAAAD8QpgAAAPxAmAIAAPADYQoAAMAPPJsPQNhYunSpli1b5lPbQ4cOebfT09Nb7LfZbEpISNCAAQOUlZWl//zP/1RKSkqLdk0PYv2iuLg4JScn68orr9T06dM1evRo3w8EQKdCmAIQli699NJ2vycuLk5xcXGSGh/Mevr0aR04cEAHDhzQCy+8oKefflpf/epXW31vTEyMunfvLkkyDEOnT59WYWGhCgsLtXHjRs2aNUuzZs3q+AEBMA1hCkBYevvtt9v9nu9973t64IEHvF9XVVXptdde0y9/+UtVV1frv/7rv/SPf/yj1aD2H//xH1q8eLH3a7fbrffff1//8z//o8OHD2vp0qUaO3assrKyOnZAAEzDNVMA0EEJCQn61re+pUceeUSS5HQ6tWHDBp/ea7fbdc0112j58uWKimr8/9o///nPQasVQPAQpgDAT7fddpsiIhp/ne7bt69d7x0wYIBSU1MlSR9//HGgSwMQAoQpAPBTTEyMevbsKanx1F97GYYhSfJ4PIEsC0CIEKYAwE9Op1OnT5+WJCUmJrbrvUePHtWnn34qSerfv3/AawMQfFyADiAsXXfddW3uW716tYYNG+ZzXy+88IJ3dumKK67w6T3nX4BeX18vSfrmN7/p8/cE0HkQpgCEpRMnTrS5ryncXEhDQ4M+++wz/eUvf9EzzzwjSerZs6emTp3aavu//vWv2rlzp6TG03rl5eVqaGjw7v/2t7+tSZMmtecQAHQShCkAYen8RTl9tWzZsjYX/ezVq5eWLl3a5mm+uro61dXVtXg9OjpaS5Ys0Y033tjuegB0DoQpAPDR+Yt22mw2xcfHq3///srKytI3v/lNJSUltfneqVOneteZcrlccjgcWrVqlTZs2KAFCxYoNTW1XacWAXQehCkA8NEXF+3sqOjoaKWlpemJJ56QJG3YsEE/+tGPtHHjRnXr1s3v/gGEFnfzAYCJ5syZo+7du+uTTz7RmjVrzC4HQAcQpgDARImJibr77rslSX/4wx9UUVFhckUA2oswBQAm+/a3v624uDhVVVVp5cqVZpcDoJ0IUwBgsp49e+pb3/qWJOl///d/derUKZMrAtAehCkA6AS+973vKSYmRk6nU88++6zZ5QBoB8IUAHQCvXv39q6A/vzzz+v48eMmVwTAVzaj6RkIAAAAaDdmpgAAAPxAmAIAAPADYQoAAMAPhCkAAAA/EKYAAAD8QJgCAADwA2EKAADAD4QpAAAAPxCmAAAA/ECYAgAA8ANhCgAAwA+EKQAAAD8QpgAAAPxAmAIAAPDD/w9M84XQ2MCX3wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = model.predict_proba(X_train)[:, 1]\n",
    "#display(model.classes_)\n",
    "fprs, tprs, T = roc_curve(Y_train, p)\n",
    "\n",
    "plt.plot(fprs, tprs)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 4\n",
    "\n",
    "### Grading Scheme\n",
    "\n",
    "Your grade for Question 4 will be based on your model’s accuracy when making predictions on the training set and your model’s accuracy when making predictions on the test set. The tables below provide scoring guidelines. If your accuracy lies in a particular range, you will receive the number of points associated with that range.\n",
    "\r",
    "**Important**: While your training accuracy can be checked at any time in this notebook, your test accuracy can only be checked by submitting your model’s predictions to Gradescope. **You may only submit to Gradescope 3 times per day to meet the threshold**. In the case that you are approved for an extension, you are granted 3 more submissions for each day the deadline has been extended. Plan ahead to make sure you have enough time to fine-tune your model! The thresholds are as follows:\n",
    "\n",
    "Points | 5 | 3 | 1.5 | 0\n",
    "--- | --- | --- | --- | ---\n",
    "**Training** Accuracy | 85% and Above | \\[80, 85) | \\[70, 80) | Below 70%\n",
    "\n",
    "Points | 10 | 6 | 3 | 0\n",
    "--- | --- | --- | --- | ---\n",
    "**Testing** Accuracy | 85% and Above | \\[80, 85) | \\[70, 80) | Below 70%\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 4a: Train Predictions\n",
    "Assign your predictions for the class of each data point in the training set `train` to the variable `train_predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T00:27:38.650695Z",
     "start_time": "2019-04-02T00:27:38.469233Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q10-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8839345135099161"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "# print your training accuracy \n",
    "training_accuracy = np.mean(train_predictions == train[\"spam\"])\n",
    "training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4a</pre></strong> passed! 🚀</p>"
      ],
      "text/plain": [
       "q4a results: All test cases passed!"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 4b: Test Set Predictions\n",
    "\n",
    "The following code will write your predictions on the test dataset to a CSV file. **You will need to submit this file to the \"Project B2 Test Set Predictions\" assignment on Gradescope to get credit for this question.**\n",
    "\n",
    "Assign your predictions for the class of each data point in the test set `test` to a 1-dimensional array called `test_predictions`. **Please make sure you save your predictions to `test_predictions`, as this is how part of your score for this question will be determined.**\n",
    "\n",
    "**Remember that if you've performed transformations or featurization on the training data, you must also perform the same transformations on the test data in order to make predictions.** For example, if you've created features for the words \"drug\" and \"money\" on the training data, you must also extract the same features in order to use scikit-learn's `.predict(...)` method.\n",
    "\n",
    "**Gradescope limits you to 3 submissions per day to meet the threshold.** In the case that you are approved for an extension, you are granted 3 more submissions for each day the deadline has been extended.\n",
    "\n",
    "The provided tests check that your predictions are in the correct format but are worth 0 points in the *Project B2 Coding assignment*. You must additionally submit to the *Project B2 Test Set Predictions* assignment to evaluate your classifier accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T00:27:38.650695Z",
     "start_time": "2019-04-02T00:27:38.469233Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q10-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4b</pre></strong> passed! 🌟</p>"
      ],
      "text/plain": [
       "q4b results: All test cases passed!"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d15e30e2a961277d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The following cell generates a CSV file with your predictions. **You must submit this CSV file to the \"Project B2 Test Predictions\" assignment on Gradescope to get credit for this question.** You can only submit to Gradescope a maximum of 3 times per day, so please use your submissions wisely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T00:27:39.986326Z",
     "start_time": "2019-04-02T00:27:38.385Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dd1bfadcbe08b00",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a CSV file: submission_20240601_013546.csv.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Download your test prediction <a href='submission_20240601_013546.csv' download>here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You may now upload this CSV file to Gradescope for scoring.\n"
     ]
    }
   ],
   "source": [
    "# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n",
    "# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n",
    "\n",
    "# Construct and save the submission:\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": test['id'], \n",
    "    \"Class\": test_predictions,\n",
    "}, columns=['Id', 'Class'])\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = \"submission_{}.csv\".format(timestamp)\n",
    "submission_df.to_csv(filename, index=False)\n",
    "\n",
    "print('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\n",
    "display(HTML(\"Download your test prediction <a href='\" + filename + \"' download>here</a>.\"))\n",
    "print('You may now upload this CSV file to Gradescope for scoring.')#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Mila congratulates you for finishing Project B2!\n",
    "\n",
    "![](mila.jpeg)\n",
    "\n",
    "Below, you will see two cells. Running the first cell will automatically generate a PDF of all questions that need to be manually graded, and running the second cell will automatically generate a zip with your autograded answers. **You are responsible for both the coding portion (the zip from Project B2) and the written portion (the PDF with from Project B2) to their respective Gradescope portals and checking that they are the most recent copy or the copy you wish to submit (including plots and all written answers).** The coding proportion should be submitted to Project B2 Coding as a single zip file, and the written portion should be submitted to Project B2 Written as a single pdf file. When submitting the written portion, please ensure you select pages appropriately. In addition, you must submit your test prediction in Q4b to **Project B2 Test Set Predictions** for the corresponding points. \n",
    "\n",
    "If there are issues with automatically generating the PDF in the first cell, you can try downloading the notebook as a PDF by clicking on `File -> Save and Export Notebook As... -> PDF`. If that doesn't work either, you can manually take screenshots of your answers to the manually graded questions and submit those. Either way, **you are responsible for ensuring your submission follows our requirements, we will NOT be granting regrade requests for submissions that don't follow instructions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "After you have run the cell below and generated the zip file, you can open the PDF <a href='projB2.pdf' download>here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running your submission against local test cases...\n",
      "\n",
      "\n",
      "Your submission received the following results when run against available test cases:\n",
      "\n",
      "    q4a results: All test cases passed!\n",
      "\n",
      "    q4b results: All test cases passed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <p>\n",
       "                        Your submission has been exported. Click\n",
       "                        <a href=\"projB2_2024_06_01T01_35_46_795384.zip\" download=\"projB2_2024_06_01T01_35_46_795384.zip\" target=\"_blank\">here</a> to download\n",
       "                        the zip file.\n",
       "                    </p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q4a": {
     "name": "q4a",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert \"sklearn.feature_extraction.text\" not in sys.modules.keys() # Check that no additional libraries are imported\n>>> training_accuracy >= 0.7 # threshold check\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1.5
        },
        {
         "code": ">>> assert \"sklearn.feature_extraction.text\" not in sys.modules.keys() # Check that no additional libraries are imported\n>>> training_accuracy >= 0.8 # threshold check\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1.5
        },
        {
         "code": ">>> assert \"sklearn.feature_extraction.text\" not in sys.modules.keys() # Check that no additional libraries are imported\n>>> training_accuracy >= 0.85 # threshold check\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert \"sklearn.feature_extraction.text\" not in sys.modules.keys() # Check that no additional libraries are imported\n>>> isinstance(test_predictions, np.ndarray) # must be ndarray of predictions\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert \"sklearn.feature_extraction.text\" not in sys.modules.keys() # Check that no additional libraries are imported\n>>> np.array_equal(np.unique(test_predictions), np.array([0, 1])) # Must be binary labels (0 or 1) and not probabilities\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert \"sklearn.feature_extraction.text\" not in sys.modules.keys() # Check that no additional libraries are imported\n>>> len(test_predictions) == 1000 # Must be the right number of predictions\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
